

\documentclass[runningheads]{llncs}
\usepackage{biblatex}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[super]{nth}
\usepackage{caption}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{hyperref}
\graphicspath{ {./images/} }


\usepackage[scaled=.92]{mathptmx}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{index}
\usepackage{istgame}
\usepackage{multicol}

\usepackage{graphicx}
\addbibresource{refs.bib}
\begin{document}
%
\title{Negation Cue Detection using SVM and XGBoost Classifiers}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{
Sergio A. Gutierrez Maury (2647606)
}
\authorrunning{Gutierrez Maury S.A}
%
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Vrije Universiteit Amsterdam}
%
\maketitle              % typeset the header of the contribution

\begin{abstract}
\input{sections/Abstract.txt}
\end{abstract}


\section*{Introduction}


\section*{Related Work}


\section*{Data Annotation Experiment}


\section*{Building an automatic Negation Cue Classifier}

\section*{Methods}

\section*{Evaluations}

\section*{Conclusion and Discussion}







%For XGBoost, this behaviour might be explained by the fact, that despite evidence from previous research, as shown in \ref{fig:feature importance}, dependency features were not deemed important by the model. Unfortunately, since gridsearch suggested that $kernel$ should be set to $polynomial$ for the SVM models, it was not possible to extract information about feature importance for them. 

%Therefore, it seems, that at least for XGBoost, the models did not get a chance to rely on the syntatic structure of the sentence, therefore not learning any specific pattern of negation, and relying greatly on the 

%Therefore, for future research it is important to consider 

%As mentioned above, both models performed considerably worse detecting $B\_NEG$ and  $I\_NEG$ labels, than detecting $O$ labels. It is suspected, that this behaviour occurs due to a big imbalance of negation versus non-negation in the training, testing and development datasets, and it seems like performing Random Over Sampling does not solve the problem, and even decreases the performance of the model in some cases. Therefore, for further research, it is important to consider training the model on more balanced datasets and then testing them on imbalanced ones, and vice versa. That way, a robust approach can be found. 

%Moreover, from Error analysis, it seems that XGBoost with Random Over Sampling does not seem to be able to detect 'not' as non-negation in non-negating contexts. It therefore can be concluded that the model is not 'smart' enough to get the patterns of negation, and greatly relies on the token itself, as can be confirmed by the fact, that whether or not token was in the \textit{NegExpList}, was the best predictor of the model. It is, therefore, necessary to explore ways to avoid such behaviour, such as training the model on bigger datasets without the use of this feature entirely, in order to let the model pick up the patterns, rather than learning to rely so heavily on \textit{NegExpList}.














\newpage
% \section*{Conclusion and Discussion}
\printbibliography


\appendix
\section{Appendix - Work Division}


\section{Appendix - Changes With Respect to Previous Assignment}



\end{document}



 

