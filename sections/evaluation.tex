
\subsection*{Results}
The results in Tables \ref{results} and \ref{tab:ResultsonDev-dataset} suggest that the models performed well on the "O" class but had lower performance on the "B-neg" and "I-neg" classes. For both models, the precision, recall, and F1-score values were close to 1 for the "O" class, indicating that the models made very few false positive and false negative predictions. However, the precision, recall, and F1-score values were lower for the "B-neg" and "I-neg" classes, suggesting that the models had a higher number of false positive and false negative predictions for these classes. Furthermore, As shown in \ref{fig:feature importance}, the most important features for XGBoost were "tag" (POS tag) and "head" (sentence root). Unfortunately, since Gridsearch suggested that $kernel$ should be set to $polynomial$ for the SVM models, it was not possible to extract information about feature importance for them.  

 
\begin{table}[!h]
{\fontsize{9}{4}
\textit{Note 1}: Both models produce the same results for both testing datasets.
\\
\textit{Note 2}: There are fewer observations because we dropped missing values.}
\centering
\begin{tabular}{cc|cccc|cccc}
\hline
 &  &  &  & XGBoost &  &  &  & SVM &  \\ \hline
Technique & Class & Precision & Recall & f1-score & Support & Precision & Recall & f1-score & Support \\ \hline
 & O & 1.00 & 1.00 & 1.00 & 8151 & 1.00 & 1.00 & 1.00 & 8151 \\
No Oversampling & B-neg & 0.89 & 0.89 & 0.89 & 129 & 0.90 & 0.89 & 0.89 & 129 \\
 & I-neg & 0.00 & 0.00 & 0.00 & 4 & 0.00 & 0.00 & 0.00 & 4 \\
Macro-avg &  & 0.63 & 0.63 & 0.63 & 8284 & 0.63 & 0.63 & 0.63 & 8284 \\ \hline
 & O & 1.00 & 0.97 & 0.98 & 8151 & 1.00 & 0.98 & 0.99 & 8151 \\
Oversampling & B-neg & 0.88 & 0.77 & 0.82 & 129 & 0.88 & 0.71 & 0.78 & 129 \\
 & I-neg & 0.01 & 0.50 & 0.02 & 4 & 0.00 & 0.00 & 0.00 & 4 \\
Macro-avg &  & 0.63 & 0.75 & 0.61 & 8284 & 0.63 & 0.56 & 0.59 & 8284 \\ \hline
\end{tabular}

\smallskip
\caption{Experiment Results on Tests Datasets}
%\smallskip
\label{results}
\end{table}
 
The use of oversampling had a limited impact on the overall performance of the models, with the macro-average precision, recall, and F1-score values being slightly higher for the oversampled data compared to the non-oversampled data. However, it is important to note that oversampling can have limitations, such as potentially causing overfitting and reduced interpretability of the model. 

\begin{table}[!h]
{\fontsize{9}{4}
\textit{Note}: There are fewer observations because we dropped missing values.}
\centering
\begin{tabular}{cc|cccc|cccc}
\hline
 &  &  &  & XGBoost &  &  &  & SVM &  \\ \hline
Technique & Class & Precision & Recall & f1-score & Support & Precision & Recall & f1-score & Support \\ \hline
 & O & 1.00 & 1.00 & 1.00 & 12375 & 1.00 & 1.00 & 1.00 & 12375 \\
No Oversampling & B-neg & 0.84 & 0.80 & 0.82 & 168 & 0.93 & 0.79 & 0.85 & 168 \\
 & I-neg & 0.00 & 0.00 & 0.00 & 3 & 0.00 & 0.00 & 0.00 & 3 \\
Macro-avg &  & 0.61 & 0.60 & 0.61 & 12546 & 0.64 & 0.59 & 0.62 & 12546 \\ \hline
 & O & 1.00 & 0.98 & 0.99 & 12375 & 1.00 & 0.98 & 0.99 & 12375 \\
Oversampling & B-neg & 0.91 & 0.68 & 0.78 & 168 & 0.91 & 0.64 & 0.75 & 168 \\
 & I-neg & 0.00 & 0.00 & 0.00 & 3 & 0.00 & 0.00 & 0.00 & 3 \\
Macro-avg &  & 0.63 & 0.56 & 0.59 & 12546 & 0.64 & 0.54 & 0.58 & 12546 \\ \hline
\end{tabular}
\caption{Experiment Results on Dev-Dataset}
\label{tab:ResultsonDev-dataset}
\end{table}

Moreover, Figure \ref{fig:confusion_matrix} shows the confusion matrices of these 4 models on the tests sets. For XGBoost with oversampling, the model correctly classified 7965 samples as positive (O), 99 samples as B-neg, and 2 samples as I-neg. However, it misclassified 174 samples as B-neg, 1 sample as I-neg, and 12 samples as O. For SVM with oversampling, the model correctly classified 7984 samples as O, 91 samples as B-neg, and 0 samples as I-neg. However, it misclassified 156 samples as B-neg, 9 samples as I-neg, and 11 samples as O. For XGBoost without oversampling, the model correctly classified 8138 samples as O, 115 samples as B-neg, and 0 samples as I-neg. However, it misclassified 13 samples as B-neg, and 3 samples as I-neg. For SVM without oversampling, the model correctly classified 8139 samples as O, 115 samples as B-neg, and 0 samples as I-neg. However, it misclassified 12 samples as B-neg, and 3 samples as I-neg. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=1\textwidth]{images/confusion_matrices.pdf}
    \caption{Confusion Matrices}
    \label{fig:confusion_matrix}
\end{figure}

In general, The results indicate that the XGBoost model with oversampling performed better than the SVM model with oversampling, with higher precision and recall scores for the positive class and the B-neg class. However, both models without oversampling performed similarly and had better performance for the positive class but lower performance for the B-neg and I-neg class. However, further improvement is required for the "B-neg" and "I-neg" classes. Further experimentation on more balanced datasets is necessary to determine if an improvement in performance for these classes can be achieved.

\begin{figure}[!h]
    \centering
    \includegraphics[width=1\textwidth]{images/feature importance.png}
    \caption{Feature Importance}
    \label{fig:feature importance}
\end{figure}


\subsection*{Error Analysis}
